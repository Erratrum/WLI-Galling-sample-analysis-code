{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83e0f181-b560-4c08-8bc7-110806018c34",
   "metadata": {},
   "source": [
    "# Initalize libaries and file name\n",
    "## !!!(YOU NEED TO PIP INSTALL h5py)!!! \"conda install h5py\" in console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ed041-1405-4ba9-9b56-b47e9755fec5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "file_name = 'ACa-01_25x1.xyz'\n",
    "\n",
    "# These need to be defined based on resolution, and hence and predefined before running the rest of the code\n",
    "Xres = 3.484 #um\n",
    "Yres = Xres #um\n",
    "\n",
    "# Set font size here\n",
    "fsize = 20\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#Grab those libaries, I ain't writing shit\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Set global font to Times New Roman and font size to 10pt\n",
    "mpl.rcParams['font.family'] = 'Times New Roman'\n",
    "mpl.rcParams['font.size'] = 10\n",
    "\n",
    "import random\n",
    "from statistics import mean\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "#from matplotlib.mlab import griddata\n",
    "from scipy import interpolate\n",
    "import h5py\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Create the output file name based on the input file name\n",
    "output_file_name = file_name.replace('.xyz', '_piv.xyz')\n",
    "\n",
    "# Replace the file extension for the output CSV file\n",
    "saving_file_name = file_name.replace('.xyz', '_processed.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af2c22e-9160-48a6-bf24-796d25c90439",
   "metadata": {},
   "source": [
    "# This is the conversion of the Zygo data to format the code wants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ea57e-d1ad-4a98-bb1c-1751c989b4fa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Read the CSV file, treating multiple spaces as a single delimiter\n",
    "df = pd.read_csv(file_name, sep='\\\\s+',skiprows=14)\n",
    "print('Read the CSV file')\n",
    "\n",
    "# Drop the last column\n",
    "df = df.iloc[:, :-1]\n",
    "print('Dropped the last column')\n",
    "\n",
    "# Replace \"No\" with NaN\n",
    "df.replace(\"No\", np.nan, inplace=True)\n",
    "df = df.iloc[:-1]\n",
    "print('Replaced \"No\" with NaN and dropped the last row')\n",
    "\n",
    "# Assuming the DataFrame has the structure [X, Y, Z]\n",
    "df.columns = ['X', 'Y', 'Z']  # Assign column names if needed\n",
    "df['X'] = df['X'].astype('int64')\n",
    "df['Y'] = df['Y'].astype('int64')\n",
    "print(df)\n",
    "\n",
    "# Pivot the DataFrame to create the 2D map\n",
    "pivot_table = df.pivot(index='Y', columns='X', values='Z')\n",
    "print('Pivoted the DataFrame')\n",
    "\n",
    "# Save the cleaned and pivoted DataFrame to the new file\n",
    "pivot_table.to_csv(output_file_name, index=0, header=1)\n",
    "print(f\"Saved processed data to {output_file_name}\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Function execution time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af09ae6-8a37-41c5-8721-5904dca49573",
   "metadata": {},
   "source": [
    "# Main body of the code, does missing data interpolation and tilt correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d281d1-795c-4e2e-8f27-daadf8df3357",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "#Step 1: read the data\n",
    "#------------#------------#------------#------------#------------#------------#------------#------------\n",
    "\n",
    "A = pd.read_csv(output_file_name)\n",
    "\n",
    "\n",
    "edge = 0.2 #distance (mm) from sample edges to be ignored during tilt correction\n",
    "movingaverage = 15\n",
    "stdrange = 1 #Number of standard deviations from mean which is accepted\n",
    "movav = movingaverage - 1\n",
    "print('Edge size / mm: ', edge)\n",
    "\n",
    "#This grabs all the real data from our now 2D array\n",
    "B = A.iloc[:,1:]\n",
    "\n",
    "\n",
    "#Step 2: Find the mid point\n",
    "#------------#------------#------------#------------#------------#------------#------------#------------\n",
    "\n",
    "#Important MINIUM POINT HERE, NOT MID POINT\n",
    "minpoints = 250 #Minimum number of data points in a column that we'll consider as being a valid number \n",
    "\n",
    "#Finding the centre of the sample\n",
    "for i in np.linspace(0, (B.shape[1]-1), (B.shape[1])):#[row, col]\n",
    "    Bslice = B.iloc[:,int(i)] #slice for column\n",
    "    Bfloat = Bslice.astype(np.float64) #float64 datatype necessary for np.isnan command to work\n",
    "    if np.isnan(Bfloat. values).sum()<B.shape[0]-(minpoints-1): #i.e. at least 10 data points\n",
    "        leftedge = i\n",
    "        break\n",
    "    else :\n",
    "        ()\n",
    "        \n",
    "for i in np.linspace((B.shape[1]-1), 0, (B.shape[1])):#[row, col]\n",
    "    Bslice = B.iloc[:,int(i)] #slice for column\n",
    "    Bfloat = Bslice.astype(np.float64) #float64 datatype necessary for np.isnan command to work\n",
    "    if np.isnan(Bfloat. values).sum()<B.shape[0]-(minpoints-1): #i.e. at least 10 data points\n",
    "        rightedge = i\n",
    "        break\n",
    "    else :\n",
    "        ()\n",
    "        \n",
    "        \n",
    "for i in np.linspace(0, (B.shape[0]-1), (B.shape[0])):#[row, col]\n",
    "    Bslice = B.iloc[int(i), :] #slice for column\n",
    "    Bfloat = Bslice.astype(np.float64) #float64 datatype necessary for np.isnan command to work\n",
    "    if np.isnan(Bfloat. values).sum()<B.shape[1]-(minpoints-1): #i.e. at least 10 data points\n",
    "        topedge = i\n",
    "        break\n",
    "    else :\n",
    "        ()\n",
    "        \n",
    "for i in np.linspace((B.shape[0]-1), 0, (B.shape[0])):#[row, col]\n",
    "    Bslice = B.iloc[int(i), :] #slice for column\n",
    "    Bfloat = Bslice.astype(np.float64) #float64 datatype necessary for np.isnan command to work\n",
    "    if np.isnan(Bfloat. values).sum()<B.shape[1]-(minpoints-1): #i.e. at least 10 data points\n",
    "        bottomedge = i\n",
    "        break\n",
    "    else :\n",
    "        ()\n",
    "        \n",
    "        \n",
    "        \n",
    "ymid = mean((leftedge, rightedge)) #since the dataset will be transposed\n",
    "xmid = mean((topedge, bottomedge)) #since the dataset will be transposed\n",
    "\n",
    "\n",
    "#Transpose to match physical specimen\n",
    "dfraw1 = (pd.DataFrame(data=B).T).astype(float)\n",
    "dfraw = pd.DataFrame(data=dfraw1)\n",
    "dfnew = dfraw*1\n",
    "\n",
    "\n",
    "#Define sample centres: X & Y apparently swapped due to dataframe being transposed after xmid and ymid were found\n",
    "Y0 = xmid\n",
    "X0 = ymid\n",
    "\n",
    "print('Left Edge column number: ', leftedge)\n",
    "print('Right Edge column number: ', rightedge)\n",
    "print('Top Edge column number: ', topedge)\n",
    "print('Bottom Edge column number: ', bottomedge)\n",
    "print('X0: ', X0)\n",
    "print('Y0: ', Y0)\n",
    "print('-----------------------------------------')\n",
    "\n",
    "#Define X & Y axes from dataset\n",
    "\n",
    "# #trying to add px back in\n",
    "# px = Xres*Yres\n",
    "# #DANGER DANGER DOM ADDED THIS CODE\n",
    "\n",
    "X = (np.linspace(0, dfraw.shape[1]-1, dfraw.shape[1])-X0)*Xres/1000 # 1px = 2.554862 um\n",
    "\n",
    "Y = (np.linspace(0, dfraw.shape[0]-1, dfraw.shape[0])-Y0)*Yres/1000 # 1px = 2.558354 um\n",
    "\n",
    "\n",
    "#Step 3: Cut off the edges of the data after filtering\n",
    "#------------#------------#------------#------------#------------#------------#------------#------------\n",
    "\n",
    "#New, simpler edge removal 5/2/2021 - trying it before filtering 22/2/2021\n",
    "#Removing Y-edges\n",
    "Yedge = 1*dfraw\n",
    "\n",
    "\n",
    "#Construction of outer and inner radii to remove edge effects\n",
    "meanres = (Xres+Yres)/2000 #in mm, different resolution in X & Y\n",
    "rout = (6.35 - edge)/meanres #in px\n",
    "rin = (3.1875 + edge)/meanres\n",
    "\n",
    "\n",
    "#Outside of left outer edge (i.e. i<Xoutneg)\n",
    "for i in range(0, int(X0-rout)+1, 1):\n",
    "    Yedge.iloc[i,:] = np.nan\n",
    "\n",
    "#Outside of right outer edge (i.e. i>Xoutneg)\n",
    "for i in range(int(X0+rout)+1, dfraw.shape[0], 1):\n",
    "    Yedge.iloc[i,:] = np.nan\n",
    "\n",
    "#Outside of lower outer edge (i.e. i<Youtneg)\n",
    "for i in range(0, int(Y0-rout)+1, 1):\n",
    "    Yedge.iloc[:, i] = np.nan\n",
    "\n",
    "#Outside of upper outer edge (i.e. i>Youtneg)\n",
    "for i in range(int(Y0+rout)+1, dfraw.shape[1], 1):\n",
    "    Yedge.iloc[:, i] = np.nan\n",
    "     \n",
    "    \n",
    "#Between Xout and Xin (for both sides)\n",
    "for i in range(int(X0-rout)+1, int(X0)+1, 1):\n",
    "    Youtpos = int(Y0 + math.sqrt(rout**2 - (i-X0)**2))\n",
    "    Youtneg = int(Y0 - math.sqrt(rout**2 - (i-X0)**2))\n",
    "    \n",
    "    Yedge.iloc[i, 0:Youtneg] = np.nan\n",
    "    Yedge.iloc[i, Youtpos:Yedge.shape[1]-1] = np.nan\n",
    "\n",
    "for i in range(int(X0), int(X0+rout), 1):\n",
    "    Youtpos = int(Y0 + math.sqrt(rout**2 - (i-X0)**2))\n",
    "    Youtneg = int(Y0 - math.sqrt(rout**2 - (i-X0)**2))\n",
    "\n",
    "    Yedge.iloc[i, 0:Youtneg] = np.nan\n",
    "    Yedge.iloc[i, Youtpos:Yedge.shape[1]-1] = np.nan\n",
    "\n",
    "#Between Xinneg and Xinpos (hole in middle as a single section)\n",
    "for i in range(int(X0-rin)+1, int(X0+rin)-1, 1):\n",
    "    #Outer portion\n",
    "    Youtpos = int(Y0 + math.sqrt(rout**2 - (i-X0)**2))\n",
    "    Youtneg = int(Y0 - math.sqrt(rout**2 - (i-X0)**2))\n",
    "    \n",
    "    Yedge.iloc[i,0:Youtneg] = np.nan\n",
    "    Yedge.iloc[i, Youtpos:Yedge.shape[1]-1] = np.nan\n",
    "        \n",
    "    #Inner portion\n",
    "    Yinpos = int(Y0 + math.sqrt(rin**2 - (i-X0)**2))\n",
    "    Yinneg = int(Y0 - math.sqrt(rin**2 - (i-X0)**2))\n",
    "    \n",
    "    Yedge.iloc[i, Yinneg:Yinpos] = np.nan\n",
    "\n",
    "dfi = Yedge\n",
    "\n",
    "\n",
    "#Step 4: Remove the peaks and troughs for plane tilt analysis\n",
    "#------------#------------#------------#------------#------------#------------#------------#------------\n",
    "\n",
    "#Filtering of data\n",
    "#Excluding data outside of mean+x*standarddeviations, where x = std (below) and the mean is found using a moving average\n",
    "print('Moving Point Average / - : ', movingaverage)\n",
    "print('Number of Standard Deviations from Mean Allowed: ', stdrange)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dfiflatX = np.ndarray.flatten(np.asarray(dfi))\n",
    "meanstdflatX = 1*dfiflatX\n",
    "mstdfl = 1*dfiflatX  #Need 1* so that the 'rawflat' array remains unchanged (not sure why it was changing)\n",
    "mstdflX = 1*meanstdflatX\n",
    "\n",
    "dfiflatY = np.ndarray.flatten(np.asarray(dfi.T))\n",
    "meanstdflatY = 1*dfiflatY\n",
    "mstdflY = 1*meanstdflatY\n",
    "\n",
    "\n",
    "srsX = pd.Series(mstdflX)\n",
    "srsY = pd.Series(mstdflY)\n",
    "\n",
    "\n",
    "rmX = srsX.rolling(movav+1, min_periods=1).mean()\n",
    "rsX = srsX.rolling(movav+1, min_periods=1).std()\n",
    "\n",
    "rmY = srsY.rolling(movav+1, min_periods=1).mean()\n",
    "rsY = srsY.rolling(movav+1, min_periods=1).std()\n",
    "\n",
    "        \n",
    "for i in np.linspace(int(1 + (movav/2)), (len(dfiflatX)-1-(movav/2)), len(dfiflatX)-1-movav):\n",
    "    if abs(rmX[int(i+movav/2)] - mstdflX[int(i)]) >= abs(stdrange*rsX[int(i+movav/2)]):\n",
    "        mstdflX[int(i)] = np.nan\n",
    "    elif round(mstdfl[int(i)],5)==round(rmX[int(i+movav/2)],5):\n",
    "        mstdflX[int(i)] = np.nan\n",
    "    else :\n",
    "        ()\n",
    "\n",
    "finish1 = time.time()\n",
    "print('Intermediate time (s): ', finish1-start)\n",
    "        \n",
    "for i in np.linspace(int(1 + (movav/2)), (len(dfiflatX)-1-(movav/2)), len(dfiflatX)-1-movav):\n",
    "    if abs(rmY[int(i+movav/2)] - mstdflY[int(i)]) >= abs(stdrange*rsY[int(i+movav/2)]):\n",
    "        mstdflY[int(i)] = np.nan\n",
    "    elif round(mstdfl[int(i)],5)==round(rmY[int(i+movav/2)],5):\n",
    "        mstdflY[int(i)] = np.nan\n",
    "    else :\n",
    "        ()\n",
    "\n",
    "        \n",
    "rollY = pd.DataFrame(data=np.reshape(mstdflY, (dfi.shape[1], dfi.shape[0])))\n",
    "rollYflat = np.ndarray.flatten(np.asarray(rollY.T))\n",
    "\n",
    "for i in np.linspace(int(1 + (movav/2)), (len(dfiflatX)-1-(movav/2)), len(dfiflatX)-1-movav):\n",
    "    if np.isnan(mstdflX[int(i)])==True or np.isnan(rollYflat[int(i)])==True:\n",
    "        mstdfl[int(i)]=np.nan\n",
    "    else :\n",
    "        ()\n",
    "\n",
    "\n",
    "        \n",
    "#Returning the flattened array to a 2D dataframe (after reshaping into a 2D array)\n",
    "dfedges = pd.DataFrame(data=np.reshape(mstdfl, (dfi.shape[0], dfi.shape[1])))\n",
    "#dfedges.to_csv('11.1post.movav15std30or.csv', na_rep='NaN')\n",
    "\n",
    "#Removing edges for analyses (written 20/8/2018 - notes in Book 2 p109, rewritten 04/10/2018 - notes in Book 2 p135)\n",
    "print('Edges Max height / um: ', np.amax(dfedges.max()))\n",
    "print('Edges Min height / um: ', np.amin(dfedges.min()))\n",
    "print('Edges Rt / um', np.amax(dfedges.max())-np.amin(dfedges.min()))\n",
    "print('-----------------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "finish2 = time.time()\n",
    "print('Total Filtering Time (s): ', finish2-start)\n",
    "\n",
    "\n",
    "#Step 5: Interpolate small to large in XY direction\n",
    "#------------#------------#------------#------------#------------#------------#------------#------------\n",
    "\n",
    "#Interpolate across whole sample (without edges)\n",
    "dfint1 = dfedges.interpolate(method='linear', axis=1, limit=15)\n",
    "dfint2 = dfint1.interpolate(method='linear', axis=0, limit=15)\n",
    "dfint3 = dfint2.interpolate(method='linear', axis=1, limit=30)\n",
    "dfint4 = dfint3.interpolate(method='linear', axis=0, limit=30)\n",
    "dfint5 = dfint4.interpolate(method='linear', axis=1, limit=60)\n",
    "dfint6 = dfint5.interpolate(method='linear', axis=0, limit=60)\n",
    "dfint7 = dfint6.interpolate(method='linear', axis=1, limit=120)\n",
    "dfint8 = dfint7.interpolate(method='linear', axis=0, limit=120)\n",
    "dfint9 = dfint8.interpolate(method='linear', axis=1, limit=250)\n",
    "dfint = dfint9.interpolate(method='linear', axis=0, limit=250) \n",
    "\n",
    "#Step 5.5: Re-remove edge filled in due to interpolation\n",
    "#------------#------------#------------#------------#------------#------------#------------#------------\n",
    "\n",
    "#Second edge removal\n",
    "Yedge = 1*dfint\n",
    "\n",
    "#Outside of left outer edge (i.e. i<Xoutneg)\n",
    "for i in range(0, int(X0-rout)+1, 1):\n",
    "    Yedge.iloc[i,:] = np.nan\n",
    "\n",
    "#Outside of right outer edge (i.e. i>Xoutneg)\n",
    "for i in range(int(X0+rout)+1, dfraw.shape[0], 1):\n",
    "    Yedge.iloc[i,:] = np.nan\n",
    "\n",
    "    \n",
    "#Outside of lower outer edge (i.e. i<Youtneg)\n",
    "for i in range(0, int(Y0-rout)+1, 1):\n",
    "    Yedge.iloc[:, i] = np.nan\n",
    "\n",
    "#Outside of upper outer edge (i.e. i>Youtneg)\n",
    "for i in range(int(Y0+rout)+1, dfraw.shape[1], 1):\n",
    "    Yedge.iloc[:, i] = np.nan\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#Between Xout and Xin (for both sides)\n",
    "for i in range(int(X0-rout)+1, int(X0)+1, 1):\n",
    "    Youtpos = int(Y0 + math.sqrt(rout**2 - (i-X0)**2))\n",
    "    Youtneg = int(Y0 - math.sqrt(rout**2 - (i-X0)**2))\n",
    "    \n",
    "    Yedge.iloc[i, 0:Youtneg] = np.nan\n",
    "    Yedge.iloc[i, Youtpos:Yedge.shape[1]-1] = np.nan\n",
    "\n",
    "for i in range(int(X0), int(X0+rout), 1):\n",
    "    Youtpos = int(Y0 + math.sqrt(rout**2 - (i-X0)**2))\n",
    "    Youtneg = int(Y0 - math.sqrt(rout**2 - (i-X0)**2))\n",
    "\n",
    "    Yedge.iloc[i, 0:Youtneg] = np.nan\n",
    "    Yedge.iloc[i, Youtpos:Yedge.shape[1]-1] = np.nan\n",
    "\n",
    "#Between Xinneg and Xinpos (hole in middle as a single section)\n",
    "for i in range(int(X0-rin)+1, int(X0+rin)-1, 1):\n",
    "    #Outer portion\n",
    "    Youtpos = int(Y0 + math.sqrt(rout**2 - (i-X0)**2))\n",
    "    Youtneg = int(Y0 - math.sqrt(rout**2 - (i-X0)**2))\n",
    "    \n",
    "    Yedge.iloc[i,0:Youtneg] = np.nan\n",
    "    Yedge.iloc[i, Youtpos:Yedge.shape[1]-1] = np.nan\n",
    "        \n",
    "    #Inner portion\n",
    "    Yinpos = int(Y0 + math.sqrt(rin**2 - (i-X0)**2))\n",
    "    Yinneg = int(Y0 - math.sqrt(rin**2 - (i-X0)**2))\n",
    "    \n",
    "    Yedge.iloc[i, Yinneg:Yinpos] = np.nan\n",
    "\n",
    "ELI = Yedge #Where ELI stands for 'edgeless interpolated'\n",
    "\n",
    "\n",
    "\n",
    "finish3 = time.time()\n",
    "print('Interpolation Time (s): ', finish3-start)\n",
    "\n",
    "\n",
    "#Step 6: Tilt correction\n",
    "#------------#------------#------------#------------#------------#------------#------------#------------\n",
    "\n",
    "\n",
    "#Tilt Correction\n",
    "F = 1*ELI\n",
    "eliflat = np.ndarray.flatten(np.asarray(ELI))\n",
    "elimean = np.nanmean(eliflat)\n",
    "elistd = np.nanstd(eliflat)\n",
    "\n",
    "F[(F>elimean+elistd)]= np.nan\n",
    "F[(F<elimean-elistd)] = np.nan\n",
    "\n",
    "G = 1*F\n",
    "fflat = np.ndarray.flatten(np.asarray(F))\n",
    "fmean = np.nanmean(fflat)\n",
    "fstd = 2*np.nanstd(fflat)\n",
    "\n",
    "G[(G>fmean+fstd)]= np.nan\n",
    "G[(G<fmean-fstd)] = np.nan\n",
    "Gflat = np.ndarray.flatten(np.asarray(G))\n",
    "\n",
    "\n",
    "Xrep = np.tile(X,len(Y))\n",
    "Yrep = np.repeat(Y, len(X))\n",
    "\n",
    "#Finding Xslope\n",
    "LRX = pd.DataFrame({'Xrep': Xrep,'Gflat': Gflat})\n",
    "LRXclean = LRX.dropna(axis=0)\n",
    "slope, intercept = np.polyfit(LRXclean['Xrep'], LRXclean['Gflat'], 1)\n",
    "\n",
    "#Correcting Xtilt\n",
    "Xcorr = slope*X\n",
    "ELIX = ELI.subtract(Xcorr, axis='columns')\n",
    "\n",
    "#Define XTilt using correction factor\n",
    "XTilt = math.cos(np.arctan(np.nanmean(slope)/1000))\n",
    "\n",
    "#Finding Yslope\n",
    "LRY = pd.DataFrame({'Yrep': Yrep,'Gflat': Gflat})\n",
    "LRYclean = LRY.dropna(axis=0)\n",
    "slope, intercept = np.polyfit(LRYclean['Yrep'], LRYclean['Gflat'], 1)\n",
    "\n",
    "#Correcting Ytilt\n",
    "Ycorr = slope*Y\n",
    "ELIYX = ELIX.subtract(Ycorr, axis='rows')\n",
    "\n",
    "#Define YTilt using correction factor\n",
    "YTilt = math.cos(np.arctan(np.nanmean(slope)/1000))\n",
    "\n",
    "#Define new X & Y positions\n",
    "Xnew1 = X/XTilt\n",
    "Ynew1 = Y/YTilt\n",
    "\n",
    "\n",
    "\n",
    "finish4 = time.time()\n",
    "print('Time for first tilt correction (s): ', finish4-start)\n",
    "\n",
    "\n",
    "#Step 6.5: Do it again Trust me bro\n",
    "#------------#------------#------------#------------#------------#------------#------------#------------\n",
    "\n",
    "#Tilt Correction 2\n",
    "H = 1*ELIYX\n",
    "eliyxflat = np.ndarray.flatten(np.asarray(ELIYX))\n",
    "eliyxmean = np.nanmean(eliyxflat)\n",
    "eliyxstd = np.nanstd(eliyxflat)\n",
    "\n",
    "H[(H>eliyxmean+eliyxstd)]= np.nan\n",
    "H[(H<eliyxmean-eliyxstd)] = np.nan\n",
    "\n",
    "I = 1*H\n",
    "hflat = np.ndarray.flatten(np.asarray(H))\n",
    "hmean = np.nanmean(hflat)\n",
    "hstd = 2*np.nanstd(hflat)\n",
    "\n",
    "I[(I>hmean+hstd)]= np.nan\n",
    "I[(I<hmean-hstd)] = np.nan\n",
    "Iflat = np.ndarray.flatten(np.asarray(I))\n",
    "\n",
    "\n",
    "#Finding Xslope2\n",
    "LRX2 = pd.DataFrame({'Xrep': Xrep,'Iflat': Iflat})\n",
    "LRX2clean = LRX2.dropna(axis=0)\n",
    "slope, intercept = np.polyfit(LRX2clean['Xrep'], LRX2clean['Iflat'], 1)\n",
    "\n",
    "#Correcting Xtilt2\n",
    "Xcorr2 = slope*X\n",
    "ELIX2 = ELIYX.subtract(Xcorr2, axis='columns')\n",
    "\n",
    "#Define XTilt2 using correction factor\n",
    "XTilt2 = math.cos(np.arctan(np.nanmean(slope)/1000))\n",
    "\n",
    "\n",
    "#Finding Yslope2\n",
    "LRY2 = pd.DataFrame({'Yrep': Yrep,'Iflat': Iflat})\n",
    "LRY2clean = LRY2.dropna(axis=0)\n",
    "slope, intercept = np.polyfit(LRY2clean['Yrep'], LRY2clean['Iflat'], 1)\n",
    "\n",
    "#Correcting Ytilt2\n",
    "Ycorr2 = slope*Y\n",
    "ELIYX2 = ELIX2.subtract(Ycorr2, axis='rows')\n",
    "\n",
    "#Define YTilt2 using correction factor\n",
    "YTilt2 = math.cos(np.arctan(np.nanmean(slope)/1000))\n",
    "\n",
    "#Define new X & Y positions\n",
    "Xnew = Xnew1/XTilt2\n",
    "Ynew = Ynew1/YTilt2\n",
    "\n",
    "finish5 = time.time()\n",
    "print('Time for second tilt correction (s): ', finish5-start)\n",
    "\n",
    "\n",
    "#Step 7: Translating so that the most populus plane is at zero\n",
    "#------------#------------#------------#------------#------------#------------#------------#------------\n",
    "\n",
    "#Initial translation so all data >=0, which makes finding the modal bin easier\n",
    "ELIYXmin = np.amin(ELIYX2.min()) #Getting the value of ELImin\n",
    "ELIYXT = ELIYX-ELIYXmin #Translating so minimimum is at Z=0 \n",
    "\n",
    "#Fill in NaN cells as 0 (otherwise binning/histogram doesn't work)\n",
    "ELIYXT0 = ELIYXT.fillna(0)\n",
    "\n",
    "#Z-Correction: Finding the zero-plane and translating this\n",
    "intervalbins = 2\n",
    "A = np.ndarray.flatten(np.asarray(ELIYXT0))\n",
    "Amax = int(np.amax(A))\n",
    "#Set bins. Don't want to start at 0 since this will now contain what were previously NaN elements (ALL of them!) \n",
    "bins = list(range(intervalbins, Amax + intervalbins, intervalbins))\n",
    "x, y, _ = plt.hist(A, bins) #Need dataframe to be a 1D array (NOT 2D!!!)\n",
    "plt.title('Histogram showing frequency at Z-position')\n",
    "plt.xlabel('Z Position / um')\n",
    "plt.ylabel('Frequency / count')\n",
    "\n",
    "\n",
    "#Finding POSITION of modal bin i.e. where should zero-plane be\n",
    "#NB: np.argmax(x) finds number of bin (NB: starting at bin number 0) that max population is in\n",
    "#print('Position of modal bin (counts): ', intervalbins*np.argmax(x), '-', intervalbins*(np.argmax(x)+1))\n",
    "#print('Z-correction factor: ', intervalbins*(np.argmax(x)+0.5))\n",
    "\n",
    "\n",
    "#Correcting Z such that the modal plane is at zero\n",
    "ELIYXTT = ELIYXT - intervalbins*(np.argmax(x)+0.5)\n",
    "\n",
    "\n",
    "print('------------------------')\n",
    "print('Corrected Edgeless Max height / um: ', np.amax(ELIYXTT.max()))\n",
    "print('Corrected Edgless Min height / um: ', np.amin(ELIYXTT.min()))\n",
    "print('Corrected Edgless Rt / um: ', np.amax(ELIYXTT.max())-np.amin(ELIYXTT.min()))\n",
    "\n",
    "\n",
    "#Step 8: Quantify data\n",
    "#------------#------------#------------#------------#------------#------------#------------#------------\n",
    "\n",
    "#Finding Sq and Ssk (quantification of data skew)\n",
    "\n",
    "Zsortnan = np.sort(np.ndarray.flatten(np.asarray(ELIYXTT))) #Flattening the dataframe into a 1D array & ordering (doesn't matter but easy to do)\n",
    "Zsort = Zsortnan[~np.isnan(Zsortnan)] #Removing the NaN cells (enabling further operations to be performed), -ve sign to remove NaN\n",
    "Z2 = Zsort**2\n",
    "Z3 = Zsort**3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "px = 2.554862\n",
    "\n",
    "#Finding the area of the data shown (i.e. not NaN), named 'Reduced Area' (RArea for short)\n",
    "#Size of each pixel for corrected sample\n",
    "Xnewsize = px/(1000*XTilt*XTilt2)\n",
    "Ynewsize = px/(1000*YTilt*YTilt2)\n",
    "RArea = (1000*Xnewsize)*(1000*Ynewsize)*len(Zsort) #Multiplied by 1000 (twice) since Z is in um andd X/Ynewsize are in mm\n",
    "\n",
    "Sq = np.sqrt(np.sum(Z2)/RArea)\n",
    "print('Sq / - :', Sq)\n",
    "\n",
    "Ssk = (np.sum(Z3)/RArea)/(Sq**3)\n",
    "print('Ssk / um:', Ssk)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot the original data on the first subplot\n",
    "c1 = ax[0].contourf(X, Y, dfedges, 256, vmax=np.amax(dfedges), vmin=np.amin(dfedges))\n",
    "ax[0].set_title('Original Data')\n",
    "ax[0].axis('equal')\n",
    "fig.colorbar(c1, ax=ax[0], ticks=range(-800, -100, 100), label='Z Position / um')\n",
    "c1.set_clim(vmax=np.amax(dfedges), vmin=np.amin(dfedges))\n",
    "ax[0].set_xlabel('X Position / mm')\n",
    "ax[0].set_ylabel('Y Position / mm')\n",
    "ax[0].spines[\"top\"].set_visible(False)\n",
    "ax[0].spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Plot the corrected data on the second subplot\n",
    "c2 = ax[1].contourf(Xnew, Ynew, ELIYXTT, 256, vmax=np.amax(ELIYXTT), vmin=np.amin(ELIYXTT))\n",
    "ax[1].set_title('Corrected Data')\n",
    "ax[1].axis('equal')\n",
    "fig.colorbar(c2, ax=ax[1], ticks=range(-500, 500, 50), label='Z Position / um')\n",
    "c2.set_clim(vmax=np.amax(ELIYXTT), vmin=np.amin(ELIYXTT))\n",
    "ax[1].set_xlabel('X Position / mm')\n",
    "ax[1].set_ylabel('Y Position / mm')\n",
    "ax[1].spines[\"top\"].set_visible(False)\n",
    "ax[1].spines[\"right\"].set_visible(False)\n",
    "\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0) # Spread out graphs to avoid overlap\n",
    "\n",
    "# Resizing the plot area\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 12 # X-axis size\n",
    "fig_size[1] = 12 # Y-axis size\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Generate z_clean here so its not regenerated in other parts of the code\n",
    "z_clean = ELIYXTT.to_numpy().flatten()[~np.isnan(ELIYXTT.to_numpy().flatten())]\n",
    "\n",
    "print('Finished!')\n",
    "end = time.time()\n",
    "print('Time elapsed: ', end - start, ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099dfbbf-ee10-4ef9-a7ff-f8f1d4ac8160",
   "metadata": {},
   "source": [
    "# This saves and loads the data into a HDF5 file so it won't have to be processed again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c88d38-a86d-46fd-a5b7-beab71066fa7",
   "metadata": {},
   "source": [
    "#### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff41c5-5c96-47ed-9c64-e288ef5ccf08",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Xnew_grid, Ynew_grid = np.meshgrid(Xnew, Ynew)\n",
    "\n",
    "# pixel size given in mm^2\n",
    "pixel_size = ((Xres*1e-3) / (XTilt*XTilt2)) * ((Yres*1e-3) / (YTilt*YTilt2))\n",
    "print(f'Pixel size is {pixel_size:.4g} mm^2')\n",
    "\n",
    "# Save data to HDF5 file\n",
    "with h5py.File(saving_file_name, 'w') as f:\n",
    "    f.create_dataset('Xnew', data=Xnew)\n",
    "    f.create_dataset('Ynew', data=Ynew)\n",
    "    f.create_dataset('ELIYXTT', data=ELIYXTT)\n",
    "    f.create_dataset('dfnew', data=dfnew)\n",
    "    f.create_dataset('ELIX2', data=ELIX2)\n",
    "    f.attrs['pixel_size'] = pixel_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fca71f-016c-4bb8-9cf6-6a7fba6520fa",
   "metadata": {},
   "source": [
    "#### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f033f879-e2d3-4bcc-a25a-a982a7496851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from HDF5 file\n",
    "with h5py.File(saving_file_name, 'r') as f:\n",
    "    Xnew = f['Xnew'][:]\n",
    "    Ynew = f['Ynew'][:]\n",
    "    pixel_size = f.attrs['pixel_size']\n",
    "    ELIYXTT = pd.DataFrame(f['ELIYXTT'][:])\n",
    "    dfnew = pd.DataFrame(f['dfnew'][:])\n",
    "    ELIX2 = pd.DataFrame(f['ELIX2'][:])\n",
    "\n",
    "# Generate z_clean again in case processing code was not run\n",
    "z_clean = ELIYXTT.to_numpy().flatten()[~np.isnan(ELIYXTT.to_numpy().flatten())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0a6a56-e4c3-4459-bf5f-210ab527eb24",
   "metadata": {},
   "source": [
    "#### This is so dumb but look at it (3D spinning gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf57e55-1440-436d-a7d9-863a3966ffc7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import time\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Set figure size to 1920x1080 resolution with 300 DPI\n",
    "fig = plt.figure(figsize=(19.2, 10.8), dpi=300)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Parameters\n",
    "u = np.linspace(0, 2 * np.pi, 100)\n",
    "v = np.linspace(0, 2 * np.pi, 50)\n",
    "u, v = np.meshgrid(u, v)\n",
    "\n",
    "# Create the 3D contour plot\n",
    "contour = ax.contour3D(Xnew, Ynew, ELIYXTT, 150, cmap='viridis', vmax=np.amax(ELIYXTT), vmin=np.amin(ELIYXTT))\n",
    "\n",
    "# Remove gridlines, axis, and background\n",
    "ax.grid(False)\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Animation function to update view angle (top-down and rotating around y-axis)\n",
    "def update(frame):\n",
    "    ax.view_init(elev=frame % 360, azim=0)  # Elevation fixed (side view), changing azimuth to simulate left-to-right flipping\n",
    "    return fig,\n",
    "\n",
    "# Create animation\n",
    "frames = 360  # Full rotation over 360 frames\n",
    "anim = FuncAnimation(fig, update, frames=frames, interval=1000/120)\n",
    "\n",
    "# Save as GIF\n",
    "anim.save('spinning_donut.gif', writer=PillowWriter(fps=60))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# End timing for the whole process\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the timing results\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaf5bc2-ce3c-40b6-a114-9238d3b42f33",
   "metadata": {},
   "source": [
    "# Basic visualisation of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a36912-e268-4fb9-badd-6ae6e6b16258",
   "metadata": {},
   "source": [
    "#### Top down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbbfe70-92b8-4682-b71f-c9f893e2d1b6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Creates a top down 2D plot\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a figure and axis object\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create a filled contour plot\n",
    "contour = ax.contourf(Xnew, Ynew, ELIYXTT, 256, vmax=np.amax(ELIYXTT.max()), vmin=np.amin(ELIYXTT.min()))\n",
    "\n",
    "# Set the title\n",
    "# ax.set_title('Corrected Data')\n",
    "\n",
    "# Set axis to be equal\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = fig.colorbar(contour, ax=ax)\n",
    "cbar.set_label('Z Position / um', fontsize = fsize)\n",
    "\n",
    "# Use MaxNLocator to determine suitable ticks\n",
    "cbar.locator = MaxNLocator(nbins=10)  # Increase the number of bins for more ticks\n",
    "cbar.update_ticks()\n",
    "\n",
    "cbar.ax.tick_params(labelsize = fsize) \n",
    "\n",
    "# Alternatively, you can set custom ticks manually\n",
    "# cbar.set_ticks(np.linspace(np.amin(ELIYXTT.min()), np.amax(ELIYXTT.max()), num=15))\n",
    "\n",
    "# Set color limits (again, this may be redundant but included for consistency)\n",
    "contour.set_clim(vmax=np.amax(ELIYXTT.max()), vmin=np.amin(ELIYXTT.min()))\n",
    "\n",
    "# Label the axes\n",
    "ax.set_xlabel('X Position / mm', fontsize = fsize)\n",
    "plt.xticks(fontsize = fsize)                  \n",
    "ax.set_ylabel('Y Position / mm', fontsize = fsize)\n",
    "plt.yticks(fontsize = fsize)                  \n",
    "\n",
    "# Remove the top and right spines\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Adjust the layout to avoid overlap\n",
    "fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "\n",
    "# Resize the plot area\n",
    "fig.set_size_inches(160/25.4, 160/25.4)\n",
    "\n",
    "output = file_name.replace('.xyz', '_circle.png')\n",
    "fig.savefig(output, dpi=150)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# End timing for the whole process\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the timing results\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d81d14-e18f-44c4-9c61-d4e8e73cfbd8",
   "metadata": {},
   "source": [
    "#### Using a scale bar instead of tick marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4115e31-4938-4bee-a685-a55d3490e870",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a figure and axis object\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create a filled contour plot\n",
    "contour = ax.contourf(Xnew, Ynew, ELIYXTT, 256, vmax=np.amax(ELIYXTT.max()), vmin=np.amin(ELIYXTT.min()))\n",
    "\n",
    "# Set axis to be equal\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = fig.colorbar(contour, ax=ax, shrink=0.85)\n",
    "cbar.set_label('Z Position / um', fontsize=fsize)\n",
    "\n",
    "# Use MaxNLocator to determine suitable ticks\n",
    "cbar.locator = MaxNLocator(nbins=10)\n",
    "cbar.update_ticks()\n",
    "\n",
    "cbar.ax.tick_params(labelsize=fsize)\n",
    "\n",
    "# Set color limits\n",
    "contour.set_clim(vmax=np.amax(ELIYXTT.max()), vmin=np.amin(ELIYXTT.min()))\n",
    "\n",
    "# Turn off ticks and labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "\n",
    "# Remove all spines\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"bottom\"].set_visible(False)\n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "\n",
    "# Add a scale bar of 10mm in the bottom left corner\n",
    "scalebar_length = 5 #mm\n",
    "x_pos = -6\n",
    "y_pos = -7\n",
    "ax.plot([x_pos, x_pos + scalebar_length], [y_pos, y_pos], color='black', lw=10)  # Thicker scale bar\n",
    "ax.text(x_pos, y_pos - 0.02 * (ax.get_ylim()[1] - ax.get_ylim()[0]), '5 mm', fontsize=fsize, va='top')\n",
    "\n",
    "# Resize the plot area\n",
    "fig.set_size_inches(160/25.4, 160/25.4)\n",
    "\n",
    "output = file_name.replace('.xyz', '_circle_scalebar.png')\n",
    "fig.savefig(output, dpi=150)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# End timing for the whole process\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the timing results\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f58240-1eab-4556-aed6-573eaaba386a",
   "metadata": {},
   "source": [
    "#### Side on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fab947f-174a-4030-abce-0bcccee12756",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Creates a side on 2D plot\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Generate X values as indices\n",
    "x_values = np.arange(len(z_clean))\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(160/25.4, 80/25.4))\n",
    "plt.scatter(x_values, z_clean, alpha = 0.05, s = 2)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Height/μm')\n",
    "output = file_name.replace('.xyz', '_2D.png')\n",
    "\n",
    "\n",
    "# Remove top and right spines\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.savefig('2ndtilt_slice', dpi=150)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# End timing for the whole process\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the timing results\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc6ad4-2c7b-4780-8bd1-ace56b4406e1",
   "metadata": {},
   "source": [
    "#### 3D (not currently saved as image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca17e72-1079-4bb7-b47e-98ccfc59715f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Creates a fun 3D plot\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a figure and an axes for 3D plotting\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create the 3D contour plot\n",
    "contour = ax.contour3D(Xnew, Ynew, ELIYXTT, 150, cmap='viridis', vmax=np.amax(ELIYXTT), vmin=np.amin(ELIYXTT))\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('X axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "ax.set_zlabel('Z axis')\n",
    "ax.set_title('ELIYXTT')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# End timing for the whole process\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the timing results\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c0c399-bf1b-40f0-bb1b-2b47adccc051",
   "metadata": {},
   "source": [
    "# This code quantifies surface roughness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfceff01-c6aa-48e5-b0b2-818f5c70246f",
   "metadata": {},
   "source": [
    "#### This code finds the Root mean square of the surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212cac6-1a2a-42d8-abd9-780348e11d7d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the mean\n",
    "mean_value = np.mean(z_clean)\n",
    "print(f\"Mean of the array: {mean_value:.4g} µm\")\n",
    "\n",
    "# Calculate squared differences from the mean\n",
    "squared_differences = np.square(z_clean - mean_value)\n",
    "print(\"Squared differences from the mean:\", squared_differences)\n",
    "\n",
    "# Calculate the mean of the squared differences\n",
    "mean_of_squared_differences = np.mean(squared_differences)\n",
    "print(f\"Mean of the squared differences: {mean_of_squared_differences:.4g} µm²\")\n",
    "\n",
    "# Calculate the RMS value\n",
    "rms_value = np.sqrt(mean_of_squared_differences)\n",
    "print(f\"The RMS value of the 2D array is: {rms_value:.4g} µm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f674b0d-c195-4409-92fe-977322d1ceb4",
   "metadata": {},
   "source": [
    "#### This code uses top 5 and bottom 5 % of datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f1762b-c21c-4195-881e-c01a303c2167",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the percentage for top 5% and bottom 5%\n",
    "percentile_cutoff = 0.05\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "sorted_values = np.sort(z_clean)\n",
    "\n",
    "# Shift the data so that the mean is at 0\n",
    "shifted_values = sorted_values\n",
    "\n",
    "# Recalculate cumulative counts\n",
    "cumulative_counts = np.arange(1, len(shifted_values) + 1)\n",
    "# Convert counts to normalized percentages\n",
    "percentage_below = cumulative_counts / len(shifted_values)\n",
    "\n",
    "# Calculate the number of data points that corresponds to 5% of the total data\n",
    "n_points = len(shifted_values)\n",
    "cutoff_count = int(n_points * percentile_cutoff)\n",
    "\n",
    "# Select the bottom 5% and top 5% points\n",
    "bottom_5_percent_values = shifted_values[:cutoff_count]\n",
    "top_5_percent_values = shifted_values[-cutoff_count:]\n",
    "\n",
    "# Find the point closest to the mean (0) for the bottom 5% and top 5%\n",
    "closest_bottom_5_percent = bottom_5_percent_values[np.abs(bottom_5_percent_values).argmin()]\n",
    "closest_top_5_percent = top_5_percent_values[np.abs(top_5_percent_values).argmin()]\n",
    "\n",
    "# Calculate the height value at the 5% cutoff\n",
    "height_at_bottom_5_percent = shifted_values[cutoff_count - 1]\n",
    "height_at_top_5_percent = shifted_values[-cutoff_count]\n",
    "\n",
    "#Finding the sample area and galled area\n",
    "SA = math.pi*(6.35**2 - 3.1875**2) #From ASTM G196 sample drawing\n",
    "\n",
    "# Plot the cumulative frequency distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(percentage_below, shifted_values)\n",
    "\n",
    "# Plot the point closest to the mean for the bottom 5% and top 5%\n",
    "plt.plot(percentage_below[np.searchsorted(shifted_values, closest_bottom_5_percent)],\n",
    "         closest_bottom_5_percent, 'ro', label=f'Closest Bottom 5% ({closest_bottom_5_percent:.2f})')\n",
    "\n",
    "plt.plot(percentage_below[np.searchsorted(shifted_values, closest_top_5_percent)],\n",
    "         closest_top_5_percent, 'bo', label=f'Closest Top 5% ({closest_top_5_percent:.2f})')\n",
    "\n",
    "# Plot the shifted mean point (now zero)\n",
    "plt.plot(percentage_below[np.searchsorted(shifted_values, 0)], 0, 'go', label=f'Zero-plane and mean (0)')\n",
    "\n",
    "# Remove top and right spines\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Cumulative Frequency')\n",
    "plt.ylabel('Height/um')\n",
    "plt.legend(frameon=0)\n",
    "plt.tight_layout\n",
    "plt.savefig('points5%.png', dpi = 150)\n",
    "plt.show()\n",
    "\n",
    "# Volumes in mm^3 for 5% data points\n",
    "volumes_below_lower_bound = np.sum(bottom_5_percent_values/1000 * pixel_size)\n",
    "volumes_above_upper_bound = np.sum(top_5_percent_values/1000 * pixel_size)\n",
    "\n",
    "# Calculate number of points and percentages\n",
    "points_below_lower_bound = len(bottom_5_percent_values)\n",
    "points_above_upper_bound = len(top_5_percent_values)\n",
    "\n",
    "percentage_bottom_5_percent = points_below_lower_bound / len(shifted_values) * 100\n",
    "percentage_top_5_percent = points_above_upper_bound / len(shifted_values) * 100\n",
    "\n",
    "# Print the results\n",
    "print(f'Bottom 5% points, area of {points_below_lower_bound * pixel_size:.4g} mm² ({percentage_bottom_5_percent:.2f}% of points)')\n",
    "print(f'Top 5% points, area of {points_above_upper_bound * pixel_size:.4g} mm² ({percentage_top_5_percent:.2f}% of points)')\n",
    "print('\\n')\n",
    "# Print percentages relative to the sample area\n",
    "print(f'Using calculated area of sample to be {SA:.4g} mm²')\n",
    "print(f'Below lower bound: {points_below_lower_bound * pixel_size / SA * 100:.4g}%')\n",
    "print(f'Above upper bound: {points_above_upper_bound * pixel_size / SA * 100:.4g}%')\n",
    "print('\\n')\n",
    "# Print volumn of peak and trough in mm^3\n",
    "print(f'Trough volume of {abs(volumes_below_lower_bound):.4g} mm³')\n",
    "print(f'Peak volume of {volumes_above_upper_bound:.4g} mm³')\n",
    "print(f'Total galled volume of {abs(volumes_below_lower_bound) + volumes_above_upper_bound:.4g} mm³')\n",
    "print('\\n')\n",
    "# Print the height values at 5% cutoff\n",
    "print(f'Height at 5% cutoff (bottom): {height_at_bottom_5_percent:.4g} µm')\n",
    "print(f'Height at 5% cutoff (top): {height_at_top_5_percent:.4g} µm')\n",
    "print(f'Range of the data {height_at_top_5_percent - height_at_bottom_5_percent:.4g} µm')\n",
    "print('\\n')\n",
    "\n",
    "# End timing for the whole process\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the timing results\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5901768f-d957-43ba-aed3-c827987236a2",
   "metadata": {},
   "source": [
    "#### This version uses 5% by range so anything below or above the 5% mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47afc11-8642-4edc-a4f5-c5b6c761c328",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "sorted_values = np.sort(z_clean)\n",
    "\n",
    "# Shift the data so that the mean is at 0\n",
    "shifted_values = sorted_values\n",
    "\n",
    "# Recalculate cumulative counts\n",
    "cumulative_counts = np.arange(1, len(shifted_values) + 1)\n",
    "# Convert counts to normalized percentages\n",
    "percentage_below = cumulative_counts / len(shifted_values)\n",
    "\n",
    "# Calculate range and determine the top and bottom 5%\n",
    "data_range = np.max(shifted_values) - np.min(shifted_values)\n",
    "lower_bound = np.min(shifted_values) + 0.05 * data_range\n",
    "upper_bound = np.max(shifted_values) - 0.05 * data_range\n",
    "\n",
    "# Filter values outside the acceptable range\n",
    "below_lower_bound_values = shifted_values[shifted_values < lower_bound]\n",
    "above_upper_bound_values = shifted_values[shifted_values > upper_bound]\n",
    "\n",
    "# Calculate how many points are outside the acceptable range\n",
    "points_below_lower_bound = len(below_lower_bound_values)\n",
    "points_above_upper_bound = len(above_upper_bound_values)\n",
    "\n",
    "percentage_below_lower_bound = points_below_lower_bound / len(shifted_values) * 100\n",
    "percentage_above_upper_bound = points_above_upper_bound / len(shifted_values) * 100\n",
    "\n",
    "# Volume calculation for points in mm^3\n",
    "volumes_below_lower_bound = np.sum(below_lower_bound_values / 1000 * pixel_size)\n",
    "volumes_above_upper_bound = np.sum(above_upper_bound_values / 1000 * pixel_size)\n",
    "\n",
    "# Finding the sample area and galled area\n",
    "SA = math.pi * (6.35**2 - 3.1875**2)  # From ASTM G196 sample drawing\n",
    "\n",
    "# Plot the cumulative frequency distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(percentage_below, shifted_values)\n",
    "\n",
    "# Plot the values outside the acceptable range\n",
    "plt.plot(percentage_below[np.searchsorted(shifted_values, lower_bound)], lower_bound, 'ro', label=f'Lower Bound ({lower_bound:.2f})')\n",
    "plt.plot(percentage_below[np.searchsorted(shifted_values, upper_bound)], upper_bound, 'bo', label=f'Upper Bound ({upper_bound:.2f})')\n",
    "\n",
    "# Plot the shifted mean point (now zero)\n",
    "plt.plot(percentage_below[np.searchsorted(shifted_values, 0)], 0, 'go', label='Zero-plane and mean (0)')\n",
    "\n",
    "# Remove top and right spines\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Cumulative Frequency')\n",
    "plt.ylabel('Height/um')\n",
    "plt.legend(frameon=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('range5%.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Print the results\n",
    "print(f'Below lower bound: {points_below_lower_bound} points, with an area of {points_below_lower_bound * pixel_size:.4g} mm² ({percentage_below_lower_bound:.2f}% of points)')\n",
    "print(f'Above upper bound: {points_above_upper_bound} points, with an area of {points_above_upper_bound * pixel_size:.4g} mm² ({percentage_above_upper_bound:.2f}% of points)')\n",
    "print('\\n')\n",
    "# Print percentages relative to the sample area\n",
    "print(f'Using calculated area of sample to be {SA:.4g} mm²')\n",
    "print(f'Below lower bound: {points_below_lower_bound * pixel_size / SA * 100:.4g}%')\n",
    "print(f'Above upper bound: {points_above_upper_bound * pixel_size / SA * 100:.4g}%')\n",
    "print('\\n')\n",
    "# Print volume of peak and trough in mm^3\n",
    "print(f'Trough volume of {abs(volumes_below_lower_bound):.4g} mm³')\n",
    "print(f'Peak volume of {volumes_above_upper_bound:.4g} mm³')\n",
    "print(f'Total galled volume of {abs(volumes_below_lower_bound) + volumes_above_upper_bound:.4g} mm³')\n",
    "print('\\n')\n",
    "\n",
    "# End timing for the whole process\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the timing results\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e8e114-927d-412e-8406-9a8c28167e9f",
   "metadata": {},
   "source": [
    "#### This code uses threshold from mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f934911-8edb-47ce-b81b-7563a7ffc2d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Set a threshold range around the mean (which is now 0)\n",
    "threshold = 6  # Adjust this value to your needs\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "sorted_values = np.sort(z_clean)\n",
    "\n",
    "# Calculate the mean\n",
    "mean_value = sorted_values.mean()\n",
    "\n",
    "# Shift the data so that the mean is at 0\n",
    "shifted_values = sorted_values - mean_value\n",
    "\n",
    "# Recalculate cumulative counts\n",
    "cumulative_counts = np.arange(1, len(shifted_values) + 1)\n",
    "# Convert counts to normalized percentages\n",
    "percentage_below = cumulative_counts / len(shifted_values)\n",
    "\n",
    "lower_bound = -threshold\n",
    "upper_bound = threshold\n",
    "\n",
    "# --- The range is picked -----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Filter values outside the acceptable range\n",
    "below_lower_bound_values = shifted_values[shifted_values < lower_bound]\n",
    "above_upper_bound_values = shifted_values[shifted_values > upper_bound]\n",
    "\n",
    "# Calculate how many points are outside the acceptable range\n",
    "points_below_lower_bound = len(below_lower_bound_values)\n",
    "points_above_upper_bound = len(above_upper_bound_values)\n",
    "\n",
    "percentage_below_lower_bound = points_below_lower_bound / len(shifted_values) * 100\n",
    "percentage_above_upper_bound = points_above_upper_bound / len(shifted_values) * 100\n",
    "\n",
    "# Volume calculation for points in mm^3\n",
    "volumes_below_lower_bound = np.sum(below_lower_bound_values/1000 * pixel_size)\n",
    "volumes_above_upper_bound = np.sum(above_upper_bound_values/1000 * pixel_size)\n",
    "\n",
    "#Finding the sample area and galled area\n",
    "SA = math.pi*(6.35**2 - 3.1875**2) #From ASTM G196 sample drawing\n",
    "\n",
    "# Plot the cumulative frequency distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(percentage_below, shifted_values)\n",
    "\n",
    "# Plot the values outside the acceptable range\n",
    "plt.plot(percentage_below[np.searchsorted(shifted_values, lower_bound)], lower_bound, 'ro', label=f'Lower Bound ({lower_bound:.2f})')\n",
    "plt.plot(percentage_below[np.searchsorted(shifted_values, upper_bound)], upper_bound, 'bo', label=f'Upper Bound ({upper_bound:.2f})')\n",
    "\n",
    "# Plot the shifted mean point (now zero)\n",
    "plt.plot(percentage_below[np.searchsorted(shifted_values, 0)], 0, 'go', label=f'Zero-plane and mean (0)')\n",
    "\n",
    "# Remove top and right spines\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Cumulative Frequency')\n",
    "plt.ylabel('Height/um')\n",
    "plt.legend(frameon=0)\n",
    "plt.tight_layout\n",
    "plt.savefig('mean.png', dpi = 150)\n",
    "plt.show()\n",
    "\n",
    "# Print the results\n",
    "print(f'Below lower bound: {points_below_lower_bound} points, with an area of {points_below_lower_bound * pixel_size:.4g} mm² ({percentage_below_lower_bound:.2f}% of points)')\n",
    "print(f'Above upper bound: {points_above_upper_bound} points, with an area of {points_above_upper_bound * pixel_size:.4g} mm² ({percentage_above_upper_bound:.2f}% of points)')\n",
    "print('\\n')\n",
    "# Print percentages relative to the sample area\n",
    "print(f'Using calculated area of sample to be {SA:.4g} mm²')\n",
    "print(f'Below lower bound: {points_below_lower_bound * pixel_size / SA * 100:.4g}%')\n",
    "print(f'Above upper bound: {points_above_upper_bound * pixel_size / SA * 100:.4g}%')\n",
    "print('\\n')\n",
    "# Print volumn of peak and trough in mm^3\n",
    "print(f'Trough volume of {abs(volumes_below_lower_bound):.4g} mm³')\n",
    "print(f'Peak volume of {volumes_above_upper_bound:.4g} mm³')\n",
    "print(f'Total galled volume of {abs(volumes_below_lower_bound) + volumes_above_upper_bound:.4g} mm³')\n",
    "print('\\n')\n",
    "\n",
    "# End timing for the whole process\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the timing results\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ba375f-be2c-4806-a31e-74deb2d2ebe0",
   "metadata": {},
   "source": [
    "#### This code uses threshold from median (zero-plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b7d964-a6ac-4c00-99b2-ea59b18c1956",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Set a threshold range around the median\n",
    "threshold = 6  # Adjust this value to your needs\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "sorted_values = np.sort(z_clean)\n",
    "\n",
    "# Recalculate cumulative counts\n",
    "cumulative_counts = np.arange(1, len(sorted_values) + 1)\n",
    "# Convert counts to normalized percentages\n",
    "percentage_below = cumulative_counts / len(sorted_values)\n",
    "\n",
    "lower_bound = -threshold\n",
    "upper_bound = threshold\n",
    "\n",
    "# --- The range is picked -----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Filter values outside the acceptable range\n",
    "below_lower_bound_values = shifted_values[sorted_values < lower_bound]\n",
    "above_upper_bound_values = shifted_values[sorted_values > upper_bound]\n",
    "\n",
    "# Calculate how many points are outside the acceptable range\n",
    "points_below_lower_bound = len(below_lower_bound_values)\n",
    "points_above_upper_bound = len(above_upper_bound_values)\n",
    "\n",
    "percentage_below_lower_bound = points_below_lower_bound / len(sorted_values) * 100\n",
    "percentage_above_upper_bound = points_above_upper_bound / len(sorted_values) * 100\n",
    "\n",
    "# Volume calculation for points in mm^3\n",
    "volumes_below_lower_bound = np.sum(below_lower_bound_values/1000 * pixel_size)\n",
    "volumes_above_upper_bound = np.sum(above_upper_bound_values/1000 * pixel_size)\n",
    "\n",
    "#Finding the sample area and galled area\n",
    "SA = math.pi*(6.35**2 - 3.1875**2) #From ASTM G196 sample drawing\n",
    "\n",
    "\n",
    "# Plot the cumulative frequency distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(percentage_below, sorted_values)\n",
    "\n",
    "# Plot the values outside the acceptable range\n",
    "plt.plot(percentage_below[np.searchsorted(sorted_values, lower_bound)], lower_bound, 'ro', label=f'Lower Bound ({lower_bound:.2f})')\n",
    "plt.plot(percentage_below[np.searchsorted(sorted_values, upper_bound)], upper_bound, 'bo', label=f'Upper Bound ({upper_bound:.2f})')\n",
    "\n",
    "# Plot the shifted mean point (now zero)\n",
    "plt.plot(percentage_below[np.searchsorted(sorted_values, 0)], 0, 'go', label=f'Zero plane (0)')\n",
    "\n",
    "# Remove top and right spines\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Cumulative Frequency')\n",
    "plt.ylabel('Height/um')\n",
    "plt.legend(frameon=0)\n",
    "plt.tight_layout\n",
    "plt.savefig('median.png', dpi = 150)\n",
    "plt.show()\n",
    "\n",
    "# Print the results\n",
    "print(f'Below lower bound: {points_below_lower_bound} points, with an area of {points_below_lower_bound * pixel_size:.4g} mm² ({percentage_below_lower_bound:.2f}% of points)')\n",
    "print(f'Above upper bound: {points_above_upper_bound} points, with an area of {points_above_upper_bound * pixel_size:.4g} mm² ({percentage_above_upper_bound:.2f}% of points)')\n",
    "print('\\n')\n",
    "# Print percentages relative to the sample area\n",
    "print(f'Using calculated area of sample to be {SA:.4g} mm²')\n",
    "print(f'Below lower bound: {points_below_lower_bound * pixel_size / SA * 100:.4g}%')\n",
    "print(f'Above upper bound: {points_above_upper_bound * pixel_size / SA * 100:.4g}%')\n",
    "print('\\n')\n",
    "# Print volumn of peak and trough in mm^3\n",
    "print(f'Trough volume of {abs(volumes_below_lower_bound):.4g} mm³')\n",
    "print(f'Peak volume of {volumes_above_upper_bound:.4g} mm³')\n",
    "print(f'Total galled volume of {abs(volumes_below_lower_bound) + volumes_above_upper_bound:.4g} mm³')\n",
    "print('\\n')\n",
    "# End timing for the whole process\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the timing results\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4affc95c-1a56-42e8-ad78-9834a9bbc277",
   "metadata": {},
   "source": [
    "# This code helps visualize tilt correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0356f042-caf5-42a9-ba2b-c22dacd7bf96",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "data = dfnew.to_numpy()\n",
    "\n",
    "# Flatten the array to get all Z values\n",
    "z_values = data.flatten()\n",
    "\n",
    "# Generate X values as indices\n",
    "x_values = np.arange(len(z_values))\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_values, z_values, alpha = 0.05, s = 2, color = \"tab:orange\")\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Height/μm')\n",
    "output = file_name.replace('.xyz', '_2D.png')\n",
    "plt.savefig('raw_Data.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# End timing for the whole process\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the timing results\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54c9982-ecbc-4e0f-99ff-70b024b32f55",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "data = ELIX2.to_numpy()\n",
    "\n",
    "# Flatten the array to get all Z values\n",
    "z_values = data.flatten()\n",
    "\n",
    "# Generate X values as indices\n",
    "x_values = np.arange(len(z_values))\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_values, z_values, alpha = 0.05, s = 2, color = \"tab:green\")\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Height/μm')\n",
    "output = file_name.replace('.xyz', '_2D.png')\n",
    "plt.savefig('1st_tilt.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# End timing for the whole process\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the timing results\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffd4de8-7415-4d1a-90e1-99358e11f92f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Example of how you might have multiple dataframes (replace this with your actual setup)\n",
    "dataframes = [dfnew, ELIX2, ELIYXTT]\n",
    "labels = ['dfnew', 'ELIX2', 'ELIYXTT']\n",
    "colors = ['tab:orange', 'tab:green', 'tab:blue']\n",
    "\n",
    "plt.figure(figsize=(160/25.4, 80/25.4))\n",
    "\n",
    "# Iterate over each dataframe\n",
    "for idx, df in enumerate(dataframes):\n",
    "    # Convert dataframe to numpy array outside the loop\n",
    "    data = df.to_numpy()\n",
    "    \n",
    "    # Flatten the array to get all Z values\n",
    "    z_values = data.flatten()\n",
    "\n",
    "    # Downsample the data to speed up plotting, e.g., plot every 10th point\n",
    "    if idx == 0:\n",
    "        step = 2\n",
    "    else:\n",
    "        step = 10  # Change step size based on your dataset\n",
    "    \n",
    "    x_values = np.arange(len(z_values))[::step]\n",
    "    z_values = z_values[::step]\n",
    "\n",
    "    # Create the plot for each dataframe\n",
    "    plt.scatter(x_values, z_values, alpha=0.2, s=1, label=labels[idx], color=colors[idx])\n",
    "\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Z')\n",
    "legend = plt.legend(loc= 1,frameon=False)\n",
    "\n",
    "for handle in legend.legendHandles:\n",
    "    handle.set_alpha(1)\n",
    "\n",
    "# Remove the top and right spines\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('allstakced.png', dpi=150)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# End timing for the whole process\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the timing results\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e1ad12-5047-4e8a-9e89-e227ded262fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# This is Sams old galling area code, im keeping here because its good to check the code outputs the same numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367914aa-2d55-4ebc-aedd-520fb2149132",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Finding the galled area and displaced volumes using the Cumulative Frequency Distribution\n",
    "Ra = 6 #Ra in um\n",
    "\n",
    "Zsortnan = np.sort(np.ndarray.flatten(np.asarray(ELIYXTT)))\n",
    "Zsort = Zsortnan[~np.isnan(Zsortnan)]\n",
    "\n",
    "#Size of each pixel for corrected sample\n",
    "Xnewsize = 0.003484/(XTilt*XTilt2)\n",
    "Ynewsize = 0.003484/(YTilt*YTilt2)\n",
    "\n",
    "for i in range(0, len(Zsort), 1):\n",
    "    if Zsort[i]>-Ra:\n",
    "        ineg = i\n",
    "        print('ineg: ', ineg)\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "for i in range(ineg, len(Zsort), 1):\n",
    "    if Zsort[i]>Ra:\n",
    "        ipos = i\n",
    "        print('ipos: ', ipos)\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "#Finding the sample area and galled area\n",
    "SA = math.pi*(6.35**2 - 3.1875**2) #From ASTM G196 sample drawing\n",
    "\n",
    "if 100*Xnewsize*Ynewsize*(ineg+(len(Zsort)-ipos))/SA <= 0:\n",
    "    GA = 0\n",
    "else:\n",
    "    GA = 100*Xnewsize*Ynewsize*(ineg+(len(Zsort)-ipos))/SA\n",
    "\n",
    "if ineg==0:\n",
    "    DVneg = 0\n",
    "else:\n",
    "    DVneg = -np.sum(Zsort[0:ineg-1])*Xnewsize*Ynewsize/1000\n",
    "    \n",
    "DVpos = np.sum(Zsort[ipos:])*Xnewsize*Ynewsize/1000\n",
    "DVtot = DVneg + DVpos\n",
    "\n",
    "TGA = 100*Xnewsize*Ynewsize*(ineg)/SA\n",
    "PGA = 100*Xnewsize*Ynewsize*((len(Zsort)-ipos))/SA\n",
    "\n",
    "print('List length:',len(Zsort))\n",
    "print('Trough Area / %: ', TGA)\n",
    "print('Peak Area / %: ', PGA)\n",
    "print('Galled Area / %: ', GA)\n",
    "print()\n",
    "print('Trough Volume (mm3): ', DVneg)\n",
    "print('Peak Volume (mm3): ', DVpos)\n",
    "print('Total Galled Volume (mm3): ', DVtot)\n",
    "print()\n",
    "print('Xszie,Ysize:',Xnewsize*Ynewsize)\n",
    "print('Pixel size:',pixel_size)\n",
    "print('surafce area:',SA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
